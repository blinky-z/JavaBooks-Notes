# Java Concurrency In Practice, Brian Goetz

### Chapter 1: Introduction

### Что такое event loop (общее понятие)?

**Event loop (цикл событий)** - это луп, который ожидает новых ивентов, а далее передает ивент в обработчик ивента. Ивент луп работает, делая запросы к *event provider* и ожидая их (например, сокет), а затем вызывает необходимый *event handler* (диспатчит ивент. Например, обработчик http запроса).

https://en.wikipedia.org/wiki/Event_loop

Можно представить его так:
```c
while (queue.waitForMessage()) {
  queue.processNextMessage();
}
```

Новые GUI фреймворки заменили event loop на event dispatch thread (EDT).

Вообще, как связаны здесь GUI приложения и ивенты? Дело в том, что действия юзера - это все какие-то ивенты, и каждое действие пользователя должно вызывать какие-то изменения, их надо как-то обрабатывать. Поэтому event-driven парадигма так популярна в GUI приложениях.

Event loop и EDT - это все об event-driven парадигме программирования.

### Liveness hazards

Для начала, надо разобраться, что такое liveness.

*Liveness* - живучесть приложения, возможность делать какой-то прогресс, даже если конкуррентно выполняющиеся компоненты ожидают вхождения в критическую секцию.

То есть, если safety означает "nothing bad ever happens", то liveness говорит: "something good eventually happens". Liveness failure происходит, когда состояние приложение таково, что оно не может делать даже постепенный прогресс.

Существует разные варианты liveness:
- freedom from deadlock
- freedom from starvation
- freedom from livelock

### Почему вообще баги связанные с конкуррентностью тяжело обнаружимы?

Потому что многое зависит от порядка выполнения операций. Тебе постоянно надо думать, что если A произойдет перед B, произойдет после B и т.д.

---

## Part 1: Fundamentals

### Chapter 2: Thread Safety
Самое правильное возможное определение thread safety дано именно в данной книге.

- **Thread safety** - класс является thread-safe, если он ведет себя *корректно* когда используется несколькими тредами, в независимости от стратегии шедулинга или порядка операций в тредах, и без дополнительной синхронизации с вызывающей стороны.

Я не зря выделил здесь слово *корректно*: корректность - это соответствие поведения класса дизайну класса, предписанным инвариантам и пост эффектам.

- **Thread safe** класс инкапсулирует необходимую синхронизацию в реализации, так что клиентам не приходится делать синхронизацию при работе с классом.

**Про состояние объекта:**

Что такое Object's state вообще? Object's state - это дата, которая содержится в полях объекта (инстансы и статические поля).

Вообще, thread safety - это именно о состоянии, а не о коде. Мы говорим о thread safety когда смотрим на кусок кода, который инкапсулирует свое состояние, а этот кусок кода может быть объектом или целой программой.

#### Race condition

**Race condition** - это о порядке действий, об их тайминге. Race condition - это возможность некорректного результата когда два треда из-за неудачного тайминга действий могут выдать некорректный результат, сделать что-то плохое. Простой пример - инкремент int или long переменной из двух тредов с помощью операции инкремента `++` без синхронизации.

Кстати, нельзя путать термин race condition с термином *data race*, который означает то, что синхронизация не используется при работе с shared non-final полем. Мы рискуем получить дата рейс, когда пишем в переменную, которая может быть прочитана другим полем, и когда читаем переменную, в которую другой тред мог что-то записать. Дата рейсы будут разобраны позже (Chapter 16). Не все race conditions это data races, и не все data races это race conditions, но часто они могут присутствовать оба. Например, в ситуации с инкрементом есть и race condition, и data race.

Самый популярный вид race condition - это check-then-act. Сначала мы проверяем условие X, далее в зависимости от верности предиката X делаем какое-то действие, но в момент между проверкой и действием условие могло стать невалидным из-за действий другого треда. Таким образом, валидность результат зависит от тайминга действий, т.е. мы имеем race condition.

Где может быть check-then-act race condition? Самый распространенный случай - это lazy initialization (т.е. конструкция вида `if (object == null) object = new Object`).

### Locks

Локи позволяют обеспечить exclusive access к критической секции. А что такое *критичесская секция*?

**Критическая секция** может являться как shared данными, так и набором операций, которые должны быть выполнены атомарно.

То есть эти 2 утверждения:
1. Локи позволяют обеспечить exclusive access к shared данным
2. Локи нужны, чтобы превратить compound операции, такие как check-then-act и read-modify-write операции в атомарные

полностью покрываются утверждением выше.

#### Intrinsic Locks

Intrinsic Lock - лок, который построен на основе внутренней сущности класса (какого-то поля или самого объекта, т.е. this).

Пример intrinsic лока в джаве - `synchronized`. Если `synchronized` применено к методу, то для лока используется сам объект (this).

Каждый Java объект может использоваться в качестве лока. Вообще, правильнее сказать, что каждый Java объект имеет intrinsic лок (под него выделяется память когда создается новый объект), и его остается только получить с помощью `synchronized`.

#### Reentrancy

Да, тред не может получить лок, который захвачен другим тредом. Однако, intrinsic лок может быть получен снова тем же тредом, который его захватил. Свойство получить лок, который уже захвачен тем же тредом, называется **reentrancy**.

Reentrancy обозначает, что лок получается на per-thread, а не per-invocation базисе. То есть лок может получить только 1 тред, но и дальнейшее его использование возможно в том же треде.

Reentrancy реализовано так: с каждым локом ассоциируется owner тред и счетчик захватов. Если счетчик равен 0, то лок считается свободным. Когда тред захватывает лок, устанавливается owner thread и счетчик инкрементируется до 1. Когда тот же тред снова захватывает лок, то счетчик опять инкрементируется. Когда тред выходит из synchronized блока кода, счетчик декрементируется. Когда счетчик достигает 0, то лок освобождается.

### Guarding State with Locks

Нельзя думать, что локи нужны только для записи в объект - даже чтение должно производиться через этот лок. Это так по следующим причинам:
 1. Если операции записи закрывать в synchronized блок, а операции чтения нет, то операции чтения могут прочитать половинное значение, а мы, используя локи, добиваемся именно атомарности
 2. synchronized должен использоваться для чтения потому, что таким образом обеспечивается, что write happens-before read (стандарт гарантирует это для synchronized) - то есть достигается видимость изменений, осуществленных в write операциях.

Более того, если объект может быть использован несколькими тредами, то все доступы к этому объекту должны быть обеспечиваться **одним и тем же локом**. В таком случае, мы говорим, что объект guarded by this lock. Когда класс имеет инвариант, который включает в себя больше одной переменной (то есть инвариант накладывает связывает как-то эти переменные), то все эти переменные также должны быть защищены (guarded) одним и тем же локом. Это позволяет нам изменять их в единой атомарной операции, сохраняя инвариант.

Также, каждая изменяемая shared переменная должна быть защищена **только одним локом**. То есть все действия с ней должны делаться только через один лок.

### Liveness and Performance

Один совет: исключать long-running операции (это или compute-intensive или I/O blocking операции) из синхронизированных блоков кода и оставлять в таких блоках только действия, относящиеся к mutual состоянию объекта. Таким образом, мы можем не сильно замедлять производительность.

--

## Chapter 3: Sharing Objects

Мы видели, как synchronized блоки кода могут обеспечить эксклюзивный доступ к критической секции, но не стоит думать, что `synchronized` используется только для этого. В многопоточном мире есть такое понятие, как **memory visibility** - видимость изменений одного треда в других тредах. Мы хотим не только избежать race condition, но и сделать так, чтобы изменения были видимы для других тредов.

Synchronized гарантирует happens-before отношение для любого последующего вызова synchronized на том же объекте (именно на объекте, не важно какой intrinsic лок используется), то есть все действия в первом synchronized блоке произошлои гарантированно заранее перед следующим вызовом synchronized метода (а как мы знаем, JVM может менять порядок операций, поэтому это важно).

### Visibility

Видимость вообще уточенная штука. Дело в том, что изменения одного треда могут быть не видны другим тредам вообще никогда или же порядок операций может меняться.

Вот пример:
```java
public class NoVisibility {
    private static boolean ready;
    private static int number;
    private static class ReaderThread extends Thread {
        public void run() {
            while (!ready) Thread.yield();
            System.out.println(number);
        }
    }
    public static void main(String[] args) {
        new ReaderThread().start();
        number = 42;
        ready = true;
    }
}
```

Здесь может произойти 2 вещи:
1. Запись в ready может быть не видна ожидающему треду никогда - здесь проблема видимости
2. Запись в ready произойдет до записи в number, и станет видна ожидающему треду, тогда ожидающий тред выведет 0, т.е. дефолтное значение int, но здесь могло быть null в случае объекта. В любом случае, в более сложном кейсе дальнейшая работа с неустановленным значением привела бы к неправильному результату - здесь проблема reordering операций

Reordering может быть не только в JVM, но и в компиляторе и процессоре. Мы не должны ничего предпологать о порядке операций, и полагаться на это при разработке конкуррентных программ. Если же happens before гарантируется стандартом, только тогда мы можем быть уверены что одни операции выполнятся перед другими.

Простой способ избежать этого - использовать синхронизацию при доступе к shared данным.

#### Non-atomic 64 bit операции

JMM гарантирует, что store и read операции атомарны для всех типов объектов, за исключением long и double, которые не объявлены как volatile или не защищены локом. Тогда есть опасность того, что при записи одним тредов в long или double переменную другой тред увидит половинное значение: 32 бита одной совершенной операции, и 32 бита от прошлого значения, т.е. получит некорректное значение.

#### Volatile variables

Джава предлагает более слабую альтернативу синхронизации, но более производительную - **volatile**. Volatile гарантирует следующие вещи:

1. Операции с переменной, объявленной как volatile, не будут reordered и порядок для них сохранится, как в коде
2. Значения не будут кэшированы и чтение всегда получит самое последнее опубликованное значение

На самом деле, эффекты видимости volatile переменной выходят за пределы самой volatile переменной. Дело в том, что когда тред A пишет в volatile переменную и тред B последовательно читает ее значение, значения переменных, которые были видны треду A до записи в volatile переменную, становятся видны и треду B после чтения volatile переменной. То есть, о volatile можно думать так: запись в volatile - это выход из synchronized блока, а чтение из volatile - это вход в synchronized блок. Однако, не стоит сильно полагаться на это. Гораздо лучше использовать volatile только для первых 2 гарантированных вещей, а не таких эффектов видимости. Такой код опасен и сложнее понятен.

Таким образом, следует использовать *volatile* только тогда, когда они упрощают разработку политики синхронизации. Не следует их использовать, когда проверка корректности требовала бы думать о видимости других состояний. То есть, использовать volatile стоит, когда оно включает в себя только состояние самой volatile переменной.

Самый распространненый случай volatile - это completion, interruption или status flag.

Локинг гарантирует нам как visibility, так и atomicity, а volatile - только visibility.

### Publication and Escape

